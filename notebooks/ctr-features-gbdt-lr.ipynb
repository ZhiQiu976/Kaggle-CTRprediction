{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/criteo-dataset/dac/test.txt\n",
      "/kaggle/input/criteo-dataset/dac/readme.txt\n",
      "/kaggle/input/criteo-dataset/dac/train.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_train = ['Label'] + \\\n",
    "[\"I\"+str(i) for i in range(1, 14)] + \\\n",
    "['C'+str(i) for i in range(1,27)]\n",
    "\n",
    "#col_names_test = col_names_train[1:]\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/criteo-dataset/dac/train.txt', \n",
    "                       sep='\\t', names=col_names_train,\n",
    "                       chunksize=100000) # ten chunks: first 1,000,000\n",
    "\n",
    "# df_test = pd.read_csv('/kaggle/input/criteo-dataset/dac/test.txt', \n",
    "#                       sep='\\t', names=col_names_test,\n",
    "#                       chunksize=100000)\n",
    "\n",
    "# don't re-run, getting without replacement\n",
    "df_train_100 = df_train.get_chunk(1000000)\n",
    "df_test_25 = df_train.get_chunk(250000)\n",
    "\n",
    "# Using the first one million records for analysis\n",
    "# use the next 250,000 as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity of model fitting, no cross-validation process\n",
    "# directly train on df_train_100 and test for performance on df_test_25 \n",
    "\n",
    "df_train_100 = df_train_100.convert_dtypes()\n",
    "df_test_25 = df_test_25.convert_dtypes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Using the first one million records for analysis\n",
    "- Using the next 250,000 as testing data\n",
    "- for simplicity of model fitting, no cross-validation process\n",
    "- directly train on df_train_100 and test for performance on df_test_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有大量缺失的特征和标签间的相关性调查\n",
    "\n",
    "- above 70% missing: I12, C22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I12 0.770057\n",
    "p1 = sns.boxplot(x=\"Label\", y=\"I12\", data=df_train_100)\n",
    "p2 = sns.displot(df_train_100, x=\"I12\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I12_temp = df_train_100[df_train_100.I12.between(1,5)]\n",
    "p1 = sns.boxplot(x=\"Label\", y=\"I12\", data=I12_temp)\n",
    "p2 = sns.displot(I12_temp, x=\"I12\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I12_temp = df_train_100[df_train_100.I12.between(5,25)]\n",
    "p1 = sns.boxplot(x=\"Label\", y=\"I12\", data=I12_temp)\n",
    "p2 = sns.displot(I12_temp, x=\"I12\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I12与Label间无明显相关性（各个值上都出现两种标签），77%缺少 -> 可考虑舍弃该特征\n",
    "- 或对数值类特征分箱/离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C22      0.738959\n",
    "p1 = sns.catplot(x='C22', hue='Label', kind='count', data=df_train_100)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程 - GBDT\n",
    "- basing on 3idiots-preA\n",
    "- https://github.com/ycjuan/kaggle-2014-criteo\n",
    "- https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10555\n",
    "- replace all numerical missing values with -10; one-hot encoding with selection (only include dense variables)\n",
    "`target_cat_feats = ['C9-a73ee510', 'C22-', 'C17-e5ba7672', 'C26-', 'C23-32c7478e', 'C6-7e0ccccf', 'C14-b28479f6', 'C19-21ddcdc9', 'C14-07d13a8f', 'C10-3b08e48b', 'C6-fbad5c96', 'C23-3a171ecb', 'C20-b1252a9d', 'C20-5840adea', 'C6-fe6b92e5', 'C20-a458ea53', 'C14-1adce6ef', 'C25-001f3601', 'C22-ad3062eb', 'C17-07c540c4', 'C6-', 'C23-423fab69', 'C17-d4bb7bd8', 'C2-38a947a1', 'C25-e8b83407', 'C9-7cc72ec2']`\n",
    "- 特征构建逻辑: 大多数数值型特征都只含正值（I2最小值-2），-10是给NA赋了一个特殊值 （**可用其他值，范围外不影响score**）；对所有类别型特征做one-hot后只保留稠密（在原完整训练集中出现超过四百万次）的特征，因为传统gbdt不适合过分稀疏的特征矩阵（prohibitively expensive computation & memory problem），原始one-hot之后的特征需做筛选（**可根据此训练集尝试其他筛选**）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-idiots methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre1_gbdt(df_train, df_test):\n",
    "    '''\n",
    "    Function for preprocessing dataframes for gbdt model with methods in \n",
    "    Team 3idiots' solution.\n",
    "    '''\n",
    "    \n",
    "    my_dict = dict.fromkeys(col_names_train[1:14], -10)\n",
    "    my_dict.update(dict.fromkeys(col_names_train[14:], 'NA'))\n",
    "\n",
    "    df_train = df_train.fillna(my_dict) # inplace=True will change global var\n",
    "    df_test = df_test.fillna(my_dict)\n",
    "    \n",
    "#     df1 = pd.get_dummies(df_train_100, columns=df_train_100.columns[14:],\n",
    "#                          prefix=col, prefix_sep='-',\n",
    "#                          dummy_na=True, sparse=True)\n",
    "    \n",
    "    y_train = df_train.Label.values.astype('int')\n",
    "    y_test = df_test.Label.values.astype('int')\n",
    "    \n",
    "    ct = ColumnTransformer(transformers=[('encoder',\n",
    "                                      OneHotEncoder(handle_unknown='ignore'), \n",
    "                                      col_names_train[14:])],\n",
    "                       remainder='passthrough')\n",
    "    X_train = ct.fit_transform(df_train.iloc[:, 1:]) # sparse matrix\n",
    "    X_test = ct.transform(df_test.iloc[:, 1:]) # sparse matrix\n",
    "    \n",
    "    target_feats = ['encoder__x8_a73ee510', 'encoder__x21_NA',\n",
    "                    'encoder__x16_e5ba7672', 'encoder__x25_NA', \n",
    "                    'encoder__x22_32c7478e', 'encoder__x5_7e0ccccf',\n",
    "                    'encoder__x13_b28479f6', 'encoder__x18_21ddcdc9',\n",
    "                    'encoder__x13_07d13a8f', 'encoder__x9_3b08e48b',\n",
    "                    'encoder__x5_fbad5c96', 'encoder__x22_3a171ecb',\n",
    "                    'encoder__x19_b1252a9d', 'encoder__x19_5840adea',\n",
    "                    'encoder__x5_fe6b92e5', 'encoder__x19_a458ea53', \n",
    "                    'encoder__x13_1adce6ef', 'encoder__x24_001f3601',\n",
    "                    'encoder__x21_ad3062eb', 'encoder__x16_07c540c4',\n",
    "                    'encoder__x5_NA', 'encoder__x22_423fab69', \n",
    "                    'encoder__x16_d4bb7bd8', 'encoder__x1_38a947a1',\n",
    "                    'encoder__x24_e8b83407', 'encoder__x8_7cc72ec2'] \\\n",
    "    + [\"I\"+str(i) for i in range(1, 14)]\n",
    "    index_selected = [i for i, x in enumerate(ct.get_feature_names())\\\n",
    "                      if x in target_feats]\n",
    "    \n",
    "    X_train = X_train[:, index_selected]\n",
    "    X_test = X_test[:, index_selected]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = pre1_gbdt(df_train_100, df_test_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBDT model only, pre1_gbdt\n",
    "grd = GradientBoostingClassifier() # with default setting\n",
    "grd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_grd = grd.predict_proba(X_train)[:, 1] # prob of y=1\n",
    "y_pred_test_grd = grd.predict_proba(X_test)[:, 1] # prob of y=1\n",
    "score_train = log_loss(y_train, y_pred_train_grd)\n",
    "score_test = log_loss(y_test, y_pred_test_grd)\n",
    "np.round(score_train, 4), np.round(score_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training, testing : (0.4982, 0.4968)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modification on 3-idiots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre2_gbdt(df_train, df_test):\n",
    "    '''\n",
    "    Function for preprocessing dataframes for gbdt model with modification on\n",
    "    methods in Team 3idiots' solution:\n",
    "    - dropping I12;\n",
    "    - one-hot encodded features with appearance more than ..%.\n",
    "    '''\n",
    "    \n",
    "    my_dict = dict.fromkeys(col_names_train[1:14], -10)\n",
    "    my_dict.update(dict.fromkeys(col_names_train[14:], 'NA'))\n",
    "\n",
    "    df_train = df_train.fillna(my_dict) # inplace=True will change global var\n",
    "    df_test = df_test.fillna(my_dict)\n",
    "    \n",
    "    y_train = df_train.Label.values.astype('int')\n",
    "    y_test = df_test.Label.values.astype('int')\n",
    "    \n",
    "    ct = ColumnTransformer(transformers=[('encoder',\n",
    "                                      OneHotEncoder(handle_unknown='ignore'), \n",
    "                                      col_names_train[14:])],\n",
    "                       remainder='passthrough')\n",
    "    X_train = ct.fit_transform(df_train.iloc[:, 1:]) # sparse matrix\n",
    "    X_test = ct.transform(df_test.iloc[:, 1:]) # sparse matrix\n",
    "    \n",
    "    # select one-hot encodded features with appearance more than ..%\n",
    "    selected_cat = np.asarray(X_train.sum(axis=0)[:,:-13] > 500000).reshape(-1)\n",
    "    # exclude I12\n",
    "    target_feats = [i for (i, v) in zip(ct.get_feature_names(), selected_cat) if v] \\\n",
    "    + [\"I\"+str(i) for i in range(1, 12)] + ['I13']\n",
    "    index_selected = [i for i, x in enumerate(ct.get_feature_names())\\\n",
    "                      if x in target_feats]\n",
    "    \n",
    "    X_train = X_train[:, index_selected]\n",
    "    X_test = X_test[:, index_selected]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = pre2_gbdt(df_train_100, df_test_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5054, 0.5044)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBDT model only, pre2_gbdt\n",
    "grd = GradientBoostingClassifier() # with default setting\n",
    "grd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_grd = grd.predict_proba(X_train)[:, 1] # prob of y=1\n",
    "y_pred_test_grd = grd.predict_proba(X_test)[:, 1] # prob of y=1\n",
    "score_train = log_loss(y_train, y_pred_train_grd)\n",
    "score_test = log_loss(y_test, y_pred_test_grd)\n",
    "np.round(score_train, 4), np.round(score_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training, testing : (0.4987, 0.4976) - dropping I12\n",
    "- training, testing : (0.5038, 0.5027) - dropping I12 & above 40% dummies only (9 variables - `['encoder__x0_05db9164',\n",
    " 'encoder__x4_25c83c98',\n",
    " 'encoder__x7_0b153874',\n",
    " 'encoder__x8_a73ee510',\n",
    " 'encoder__x16_e5ba7672',\n",
    " 'encoder__x18_NA',\n",
    " 'encoder__x19_NA',\n",
    " 'encoder__x21_NA',\n",
    " 'encoder__x24_NA',\n",
    " 'encoder__x25_NA']`)\n",
    "- training, testing : (0.5054, 0.5044) - dropping I12 & above 50% dummies only (5 variables - `['encoder__x0_05db9164',\n",
    " 'encoder__x4_25c83c98',\n",
    " 'encoder__x7_0b153874',\n",
    " 'encoder__x8_a73ee510',\n",
    " 'encoder__x21_NA']`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discretization on numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程：GBDT+LR\n",
    "\n",
    "- 人工特征工程(+scaling) + GBDT特征 + LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
