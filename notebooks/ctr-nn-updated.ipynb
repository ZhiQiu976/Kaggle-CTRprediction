{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/criteo-dataset/dac/test.txt\n",
      "/kaggle/input/criteo-dataset/dac/readme.txt\n",
      "/kaggle/input/criteo-dataset/dac/train.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepctr[gpu]\n",
      "  Downloading deepctr-0.8.5-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from deepctr[gpu]) (2.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from deepctr[gpu]) (2.25.1)\n",
      "Collecting tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0\n",
      "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.3 MB 12 kB/s s eta 0:00:01    |███████▎                        | 89.5 MB 49.7 MB/s eta 0:00:07     |██████████████▍                 | 177.2 MB 60.4 MB/s eta 0:00:04     |███████████████▉                | 195.2 MB 63.3 MB/s eta 0:00:04     |████████████████▉               | 207.6 MB 63.3 MB/s eta 0:00:03     |█████████████████▎              | 212.5 MB 63.3 MB/s eta 0:00:03��█▋            | 242.0 MB 54.8 MB/s eta 0:00:03     |████████████████████            | 245.7 MB 54.8 MB/s eta 0:00:03██████████████▋           | 253.8 MB 54.8 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py==2.10.0->deepctr[gpu]) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py==2.10.0->deepctr[gpu]) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (2.4.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.12.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (2.4.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.15.6)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.12)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.32.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (4.7.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (1.26.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.4.0)\n",
      "Installing collected packages: tensorflow-gpu, deepctr\n",
      "Successfully installed deepctr-0.8.5 tensorflow-gpu-2.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install deepctr[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.estimator import DeepFMEstimator, DCNEstimator\n",
    "from deepctr.models import *\n",
    "from deepctr.estimator.inputs import input_fn_pandas\n",
    "from deepctr.feature_column import SparseFeat, DenseFeat, get_feature_names\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Using the first one million records for analysis\n",
    "- Using the next 250,000 as testing data\n",
    "- for simplicity of model fitting, no cross-validation process, directly train on df_train_100 and test for performance on df_test_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_train = ['label'] + \\\n",
    "[\"I\"+str(i) for i in range(1, 14)] + \\\n",
    "['C'+str(i) for i in range(1,27)]\n",
    "\n",
    "#col_names_test = col_names_train[1:]\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/criteo-dataset/dac/train.txt', \n",
    "                       sep='\\t', names=col_names_train,\n",
    "                       chunksize=100000) # ten chunks: first 1,000,000\n",
    "\n",
    "# df_test = pd.read_csv('/kaggle/input/criteo-dataset/dac/test.txt', \n",
    "#                       sep='\\t', names=col_names_test,\n",
    "#                       chunksize=100000)\n",
    "\n",
    "# don't re-run, getting without replacement\n",
    "df = df_train.get_chunk(1250000)\n",
    "\n",
    "# Using the first one million records for analysis\n",
    "# use the next 250,000 as testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepCTR\n",
    "ref: \n",
    "https://zhuanlan.zhihu.com/p/53231955\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFM\n",
    "\n",
    "- https://www.cnblogs.com/xiaoqi/p/deepfm.html\n",
    "- https://booking.ai/dont-be-tricked-by-the-hashing-trick-192a6aae3087"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "data[dense_features] = data[dense_features].fillna(0)\n",
    "target = ['label']\n",
    "\n",
    "# label encoding\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "# min-max scaler\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[SparseFeat(feat, vocabulary_size=data[feat].max()+1, embedding_dim=2) for i,feat in enumerate(sparse_features)]\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].max()+1, embedding_dim=3) \n",
    "                          for i,feat in enumerate(sparse_features)] + \\\n",
    "[SparseFeat(feat, vocabulary_size=data[feat].max()+1, embedding_dim=4, use_hash=True)\n",
    " for feat in sparse_features] + \\\n",
    "[DenseFeat(feat, 1,) for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data[:1000000], data[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input = {name:train[name] for name in feature_names}\n",
    "test_model_input = {name:test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3125/3125 - 186s - loss: 0.4933 - binary_crossentropy: 0.4808 - val_loss: 0.4903 - val_binary_crossentropy: 0.4705\n",
      "Epoch 2/20\n",
      "3125/3125 - 178s - loss: 0.4768 - binary_crossentropy: 0.4489 - val_loss: 0.5007 - val_binary_crossentropy: 0.4710\n",
      "Epoch 3/20\n",
      "3125/3125 - 178s - loss: 0.4622 - binary_crossentropy: 0.4220 - val_loss: 0.5212 - val_binary_crossentropy: 0.4767\n",
      "Epoch 4/20\n",
      "3125/3125 - 176s - loss: 0.3904 - binary_crossentropy: 0.3457 - val_loss: 0.5685 - val_binary_crossentropy: 0.5180\n",
      "Epoch 5/20\n",
      "3125/3125 - 175s - loss: 0.3425 - binary_crossentropy: 0.2976 - val_loss: 0.6252 - val_binary_crossentropy: 0.5783\n",
      "Epoch 6/20\n",
      "3125/3125 - 177s - loss: 0.3315 - binary_crossentropy: 0.2876 - val_loss: 0.6403 - val_binary_crossentropy: 0.5926\n",
      "Epoch 7/20\n",
      "3125/3125 - 176s - loss: 0.3283 - binary_crossentropy: 0.2828 - val_loss: 0.6302 - val_binary_crossentropy: 0.5807\n",
      "Epoch 8/20\n",
      "3125/3125 - 177s - loss: 0.3143 - binary_crossentropy: 0.2682 - val_loss: 0.6647 - val_binary_crossentropy: 0.6160\n",
      "Epoch 9/20\n",
      "3125/3125 - 176s - loss: 0.3080 - binary_crossentropy: 0.2619 - val_loss: 0.6755 - val_binary_crossentropy: 0.6258\n",
      "Epoch 10/20\n",
      "3125/3125 - 176s - loss: 0.3046 - binary_crossentropy: 0.2575 - val_loss: 0.6852 - val_binary_crossentropy: 0.6344\n",
      "Epoch 11/20\n",
      "3125/3125 - 176s - loss: 0.2983 - binary_crossentropy: 0.2504 - val_loss: 0.6999 - val_binary_crossentropy: 0.6488\n",
      "Epoch 12/20\n",
      "3125/3125 - 176s - loss: 0.2925 - binary_crossentropy: 0.2444 - val_loss: 0.7085 - val_binary_crossentropy: 0.6572\n",
      "Epoch 13/20\n",
      "3125/3125 - 177s - loss: 0.2888 - binary_crossentropy: 0.2404 - val_loss: 0.7054 - val_binary_crossentropy: 0.6534\n",
      "Epoch 14/20\n",
      "3125/3125 - 176s - loss: 0.2851 - binary_crossentropy: 0.2360 - val_loss: 0.7123 - val_binary_crossentropy: 0.6599\n",
      "Epoch 15/20\n",
      "3125/3125 - 177s - loss: 0.2801 - binary_crossentropy: 0.2308 - val_loss: 0.7371 - val_binary_crossentropy: 0.6846\n",
      "Epoch 16/20\n",
      "3125/3125 - 174s - loss: 0.2770 - binary_crossentropy: 0.2274 - val_loss: 0.7293 - val_binary_crossentropy: 0.6765\n",
      "Epoch 17/20\n",
      "3125/3125 - 174s - loss: 0.2743 - binary_crossentropy: 0.2244 - val_loss: 0.7509 - val_binary_crossentropy: 0.6978\n",
      "Epoch 18/20\n",
      "3125/3125 - 174s - loss: 0.2716 - binary_crossentropy: 0.2214 - val_loss: 0.7543 - val_binary_crossentropy: 0.7010\n",
      "Epoch 19/20\n",
      "3125/3125 - 174s - loss: 0.2681 - binary_crossentropy: 0.2178 - val_loss: 0.7588 - val_binary_crossentropy: 0.7055\n",
      "Epoch 20/20\n",
      "3125/3125 - 174s - loss: 0.2661 - binary_crossentropy: 0.2156 - val_loss: 0.7584 - val_binary_crossentropy: 0.7048\n",
      "test LogLoss 0.7089\n",
      "test AUC 0.7027\n"
     ]
    }
   ],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=20, verbose=2, validation_split=0.2)\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results:\n",
    "- label encoding, minmax scaler, feature embedding (4): test LogLoss 0.5877, test AUC 0.7205\n",
    "- ***label encoding, minmax scaler, feature embedding (3): test LogLoss 0.5937, test AUC 0.7256\n",
    "- label encoding, minmax scaler, feature embedding (5): divide by zero encountered in log loss\n",
    "- label encoding, minmax scaler, feature embedding (2): test LogLoss 0.5772, test AUC 0.7305\n",
    "\n",
    "- label encoding, minmax scaler, feature hashing (1000, 4): divide by zero encountered in log loss\n",
    "- **label encoding, minmax scaler, feature hashing (data[feat].max()+1, 4): test LogLoss 0.6169, test AUC 0.7125\n",
    "- label encoding, minmax scaler, feature hashing (1e6, 4): test LogLoss 0.6177, test AUC 0.712 (slow)\n",
    "\n",
    "- *label encoding, minmax scaler, feature hashing (data[feat].max()+1, 4), feature embedding (3): test LogLoss 0.638, test AUC 0.7132\n",
    "- label encoding, minmax scaler, feature hashing (data[feat].max()+1, 3), feature embedding (3): test LogLoss 0.622, test AUC 0.7172; 20 epochs, test LogLoss 0.7089, test AUC 0.7027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCN (Deep & Cross Network)\n",
    "\n",
    "- https://blog.csdn.net/u012290039/article/details/106943344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossNet parameterization: vector\n",
      "Epoch 1/20\n",
      "3125/3125 - 192s - loss: 0.4927 - binary_crossentropy: 0.4808 - val_loss: 0.4884 - val_binary_crossentropy: 0.4700\n",
      "Epoch 2/20\n",
      "3125/3125 - 183s - loss: 0.4772 - binary_crossentropy: 0.4513 - val_loss: 0.4954 - val_binary_crossentropy: 0.4685\n",
      "Epoch 3/20\n",
      "3125/3125 - 183s - loss: 0.4670 - binary_crossentropy: 0.4297 - val_loss: 0.5151 - val_binary_crossentropy: 0.4745\n",
      "Epoch 4/20\n",
      "3125/3125 - 179s - loss: 0.4019 - binary_crossentropy: 0.3592 - val_loss: 0.5591 - val_binary_crossentropy: 0.5103\n",
      "Epoch 5/20\n",
      "3125/3125 - 178s - loss: 0.3448 - binary_crossentropy: 0.3024 - val_loss: 0.6163 - val_binary_crossentropy: 0.5727\n",
      "Epoch 6/20\n",
      "3125/3125 - 179s - loss: 0.3329 - binary_crossentropy: 0.2922 - val_loss: 0.6234 - val_binary_crossentropy: 0.5791\n",
      "Epoch 7/20\n",
      "3125/3125 - 178s - loss: 0.3302 - binary_crossentropy: 0.2879 - val_loss: 0.6224 - val_binary_crossentropy: 0.5759\n",
      "Epoch 8/20\n",
      "3125/3125 - 178s - loss: 0.3174 - binary_crossentropy: 0.2740 - val_loss: 0.6548 - val_binary_crossentropy: 0.6087\n",
      "Epoch 9/20\n",
      "3125/3125 - 179s - loss: 0.3074 - binary_crossentropy: 0.2641 - val_loss: 0.6666 - val_binary_crossentropy: 0.6203\n",
      "Epoch 10/20\n",
      "3125/3125 - 182s - loss: 0.3049 - binary_crossentropy: 0.2608 - val_loss: 0.6801 - val_binary_crossentropy: 0.6321\n",
      "Epoch 11/20\n",
      "3125/3125 - 183s - loss: 0.2996 - binary_crossentropy: 0.2543 - val_loss: 0.6708 - val_binary_crossentropy: 0.6221\n",
      "Epoch 12/20\n",
      "3125/3125 - 184s - loss: 0.2920 - binary_crossentropy: 0.2462 - val_loss: 0.6929 - val_binary_crossentropy: 0.6441\n",
      "Epoch 13/20\n",
      "3125/3125 - 182s - loss: 0.2873 - binary_crossentropy: 0.2413 - val_loss: 0.6955 - val_binary_crossentropy: 0.6460\n",
      "Epoch 14/20\n",
      "3125/3125 - 182s - loss: 0.2850 - binary_crossentropy: 0.2381 - val_loss: 0.7213 - val_binary_crossentropy: 0.6710\n",
      "Epoch 15/20\n",
      "3125/3125 - 183s - loss: 0.2804 - binary_crossentropy: 0.2329 - val_loss: 0.7343 - val_binary_crossentropy: 0.6836\n",
      "Epoch 16/20\n",
      "3125/3125 - 184s - loss: 0.2765 - binary_crossentropy: 0.2287 - val_loss: 0.7305 - val_binary_crossentropy: 0.6796\n",
      "Epoch 17/20\n",
      "3125/3125 - 182s - loss: 0.2735 - binary_crossentropy: 0.2253 - val_loss: 0.7500 - val_binary_crossentropy: 0.6987\n",
      "Epoch 18/20\n",
      "3125/3125 - 180s - loss: 0.2716 - binary_crossentropy: 0.2229 - val_loss: 0.7470 - val_binary_crossentropy: 0.6951\n",
      "Epoch 19/20\n",
      "3125/3125 - 181s - loss: 0.2679 - binary_crossentropy: 0.2189 - val_loss: 0.7622 - val_binary_crossentropy: 0.7101\n",
      "Epoch 20/20\n",
      "3125/3125 - 185s - loss: 0.2663 - binary_crossentropy: 0.2170 - val_loss: 0.7501 - val_binary_crossentropy: 0.6978\n",
      "test LogLoss nan\n",
      "test AUC 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:2279: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "model2 = DCN(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model2.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model2.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=20, verbose=2, validation_split=0.2)\n",
    "pred_ans = model2.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label encoding, minmax scaler, feature hashing (1e6, 4): test LogLoss 0.6057, test AUC 0.7208\n",
    "- label encoding, minmax scaler, feature hashing (data[feat].max()+1, 4): test LogLoss 0.6228, test AUC 0.7097\n",
    "- *label encoding, minmax scaler, feature hashing (data[feat].max()+1, 4), feature embedding (3): test LogLoss 0.6279, test AUC 0.7171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
