{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/criteo-dataset/dac/test.txt\n",
      "/kaggle/input/criteo-dataset/dac/readme.txt\n",
      "/kaggle/input/criteo-dataset/dac/train.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepctr[gpu] in /opt/conda/lib/python3.7/site-packages (0.8.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from deepctr[gpu]) (2.25.1)\n",
      "Requirement already satisfied: h5py==2.10.0 in /opt/conda/lib/python3.7/site-packages (from deepctr[gpu]) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from deepctr[gpu]) (2.4.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py==2.10.0->deepctr[gpu]) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.7/site-packages (from h5py==2.10.0->deepctr[gpu]) (1.19.5)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.10.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (2.4.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.2.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.32.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.14.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.3.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.3.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.4.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (49.6.0.post20201009)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->deepctr[gpu]) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu!=1.7.*,!=1.8.*,>=1.4.0->deepctr[gpu]) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deepctr[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.estimator import DeepFMEstimator, DCNEstimator\n",
    "from deepctr.models import *\n",
    "from deepctr.estimator.inputs import input_fn_pandas\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Using the first one million records for analysis\n",
    "- Using the next 250,000 as testing data\n",
    "- for simplicity of model fitting, no cross-validation process, directly train on df_train_100 and test for performance on df_test_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_train = ['label'] + \\\n",
    "[\"I\"+str(i) for i in range(1, 14)] + \\\n",
    "['C'+str(i) for i in range(1,27)]\n",
    "\n",
    "#col_names_test = col_names_train[1:]\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/criteo-dataset/dac/train.txt', \n",
    "                       sep='\\t', names=col_names_train,\n",
    "                       chunksize=100000) # ten chunks: first 1,000,000\n",
    "\n",
    "# df_test = pd.read_csv('/kaggle/input/criteo-dataset/dac/test.txt', \n",
    "#                       sep='\\t', names=col_names_test,\n",
    "#                       chunksize=100000)\n",
    "\n",
    "# don't re-run, getting without replacement\n",
    "df = df_train.get_chunk(1250000)\n",
    "\n",
    "# Using the first one million records for analysis\n",
    "# use the next 250,000 as testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      int64\n",
       "I1       float64\n",
       "I2         int64\n",
       "I3       float64\n",
       "I4       float64\n",
       "I5       float64\n",
       "I6       float64\n",
       "I7       float64\n",
       "I8       float64\n",
       "I9       float64\n",
       "I10      float64\n",
       "I11      float64\n",
       "I12      float64\n",
       "I13      float64\n",
       "C1        object\n",
       "C2        object\n",
       "C3        object\n",
       "C4        object\n",
       "C5        object\n",
       "C6        object\n",
       "C7        object\n",
       "C8        object\n",
       "C9        object\n",
       "C10       object\n",
       "C11       object\n",
       "C12       object\n",
       "C13       object\n",
       "C14       object\n",
       "C15       object\n",
       "C16       object\n",
       "C17       object\n",
       "C18       object\n",
       "C19       object\n",
       "C20       object\n",
       "C21       object\n",
       "C22       object\n",
       "C23       object\n",
       "C24       object\n",
       "C25       object\n",
       "C26       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for simplicity of model fitting, no cross-validation process\n",
    "# directly train on df_train_100 and test for performance on df_test_25 \n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepCTR\n",
    "ref: \n",
    "https://zhuanlan.zhihu.com/p/53231955\n",
    "\n",
    "https://github.com/shenweichen/DeepCTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFM - features 1\n",
    "\n",
    "- https://deepctr-doc.readthedocs.io/en/latest/_modules/deepctr/estimator/models/deepfm.html#DeepFMEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1')\n",
    "data[dense_features] = data[dense_features].fillna(0)\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "# mix-max standardization for dense features \n",
    "\n",
    "# # Clip integer features by the 95% quantile of the total values: Above 95%: 1\n",
    "# # cont_clip = data.iloc[:,1:14].quantile(q=0.95, axis=0)\n",
    "# cont_clip = [9, 469, 49, 21, 62792.1, 386, 54, 43, 411, 1, 9, 1, 23]\n",
    "# for i in range(13):\n",
    "#     cutoff = cont_clip[i]\n",
    "#     col_name = dense_features[i]\n",
    "#     data[col_name] = np.where(data[col_name]>cutoff, cutoff, data[col_name])\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features 1: feature embedding\n",
    "\n",
    "dnn_feature_columns = []\n",
    "linear_feature_columns = []\n",
    "\n",
    "for feat in sparse_features:\n",
    "    features_cat = tf.feature_column.categorical_column_with_identity(feat, data[feat].max()+1)\n",
    "    features_embedded = tf.feature_column.embedding_column(features_cat, 3)\n",
    "    dnn_feature_columns.append(features_embedded)\n",
    "    linear_feature_columns.append(features_cat)\n",
    "for feat in dense_features:\n",
    "    features_num = tf.feature_column.numeric_column(feat)\n",
    "    dnn_feature_columns.append(features_num)\n",
    "    linear_feature_columns.append(features_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data[:1000000], data[1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dtypes, int64, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_to_dataset(dataframe, shuffle=True, batch_size=256):\n",
    "#     '''\n",
    "#     Pandas dataframe to tensorflow dataset.\n",
    "#     '''\n",
    "    \n",
    "#     dataframe = dataframe.copy()\n",
    "#     labels = dataframe.pop('Label')\n",
    "#     ds = tf.data.Dataset.from_tensor_slices((dataframe.values, labels.values))\n",
    "#     if shuffle:\n",
    "#         ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "#     ds = ds.batch(batch_size)\n",
    "    \n",
    "#     return ds\n",
    "\n",
    "# train_model_input = df_to_dataset(train)\n",
    "# test_model_input = df_to_dataset(test, shuffle=False)\n",
    "\n",
    "train_model_input = input_fn_pandas(train, sparse_features + dense_features, 'label', shuffle=True)\n",
    "test_model_input = input_fn_pandas(test, sparse_features + dense_features, None, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test LogLoss 0.5323\n",
      "test AUC 0.6985\n"
     ]
    }
   ],
   "source": [
    "model = DeepFMEstimator(linear_feature_columns, dnn_feature_columns, task='binary', \n",
    "                        config=tf.estimator.RunConfig(tf_random_seed=123))\n",
    "\n",
    "model.train(train_model_input)\n",
    "pred_ans_iter = model.predict(test_model_input)\n",
    "pred_ans = list(map(lambda x: x['pred'], pred_ans_iter))\n",
    "#\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results:\n",
    "- seed 123, embedding 4, min-max scaler: (0.531, 0.7024)\n",
    "- seed 123, embedding 6, min-max scaler: (0.5292, 0.7051)\n",
    "- seed 123, embedding 3, min-max scaler: (0.5335, 0.698)*\n",
    "- seed 123, embedding 2, min-max scaler: divide by zero encountered in log loss\n",
    "\n",
    "- seed 123, embedding 3, min-max scaler (95% by train): (0.528, 0.712)\n",
    "- seed 123, embedding 3, min-max scaler (95% by all): (0.5278, 0.712)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf demo\n",
    "# https://medium.com/ml-book/demonstration-of-tensorflow-feature-columns-tf-feature-column-3bfcca4ca5c4\n",
    "\n",
    "\n",
    "# from tensorflow.python.feature_column.feature_column import _LazyBuilder\n",
    "\n",
    "# def test_numeric():\n",
    "#     price = {'price': [[1.], [2.], [3.], [4.]]}  # 4行样本\n",
    "#     builder = _LazyBuilder(price)\n",
    "\n",
    "#     def transform_fn(x):\n",
    "#         return x + 2\n",
    "\n",
    "#     price_column = tf.feature_column.numeric_column('price', normalizer_fn=transform_fn)\n",
    "#     price_transformed_tensor = price_column._get_dense_tensor(builder)\n",
    "#     print(price_transformed_tensor)\n",
    "\n",
    "# test_numeric()\n",
    "\n",
    "\n",
    "# def test_categorical_column_with_vocabulary_list():\n",
    "#     color_data = {'color': [['R', 'R'], ['G', 'R'], ['B', 'G'], ['A', 'A']]}  # 4行样本\n",
    "#     builder = _LazyBuilder(color_data)\n",
    "#     color_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "#         'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "#     )\n",
    "    \n",
    "#     # sparse: named tuple\n",
    "#     color_column_tensor = color_column._get_sparse_tensors(builder)\n",
    "#     print('_' * 60)\n",
    "#     print(color_column_tensor.id_tensor)\n",
    "\n",
    "#     # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "#     color_column_identy = tf.feature_column.indicator_column(color_column)\n",
    "#     feature_layer = tf.keras.layers.DenseFeatures(color_column_identy)\n",
    "#     print('_' * 60)\n",
    "#     print(feature_layer(color_data))\n",
    "    \n",
    "#     # embedding column, can change dim\n",
    "#     color_column_embedding = tf.feature_column.embedding_column(color_column,\n",
    "#                                                       dimension=4) \n",
    "#     feature_layer = tf.keras.layers.DenseFeatures(color_column_embedding)\n",
    "#     print('_' * 60)\n",
    "#     print(feature_layer(color_data))\n",
    "\n",
    "# test_categorical_column_with_vocabulary_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
